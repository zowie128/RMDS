---
title: "Coursework assignment A - 2023-2024"
subtitle: "CS4125 Seminar Research Methodology for Data Science"
author: "Ella Bakker, Sam Heslenfeld, Zoë Abhelakh"
date: "27/03/2024"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "https://cran.rstudio.com"))



\tableofcontents


# Part 1 - Design and set-up of true experiment 
This experiment will evaluate the impact of music on cognitive performance of test subjects.

## The motivation for the planned research 
While anecdotal evidence and some research suggest that listening to classical music can improve cognitive abilities, 
such as memory and attention, further scientific investigation is required to validate these claims. Such research not only 
sheds light on the potential benefits of music for cognitive enhancement but also informs practical applications in various settings, 
including education, therapy, and workplace environments. Ultimately, understanding how classical music influences cognitive 
function contributes to our broader understanding of human cognition and behavior.

Further, a deeper exploration into the effects of classical music on cognitive function offers a pathway to uncovering the 
intricacies of the mind's response to auditory stimuli. In exploring this realm, this experiment aims to establish robust 
empirical evidence that can guide the development of evidence-based interventions and strategies for cognitive enhancement. 
Moreover, understanding the mechanisms through which classical music influences cognitive processes holds promise for optimizing 
learning environments, designing therapeutic interventions, and fostering creativity and productivity in professional settings. 
This pursuit not only enriches our understanding of human cognition but also underscores the transformative potential of music 
in shaping cognitive abilities and behaviors.

## The theory underlying the research  
Numerous studies have suggested that music can influence cognitive functions such as attention, memory, and problem-solving. 
One study experimented with what is known as the 'Vivaldi effect' and found that classical music significantly increases working 
memory performance compared to the condition without music \cite{mamma}. Another study found a statistically significant positive 
correlation between mindfulness, as measured by the Mindful Attention Awareness Scale (MAAS), and spatial reasoning skills, 
as measured by the Spatial Ability Practice Test 1 (SAPT1), particularly among participants exposed to a receptive music program 
for 12 weeks, indicating that long-term listening to classical music may enhance spatio-temporal reasoning abilities (Bell).

A similar study study explored the impact of preferred and non-preferred popular music, as well as classical music, on the cognitive 
performance of college students in terms of reading comprehension (Harmon). Before testing, participants listened to each music type, 
which aimed to alleviate the potential distractions music might pose during cognitive tasks. Although no significant differences were 
found in reading comprehension scores across the music conditions, the experiment raises interest in further investigating how classical 
music might affect cognitive performance when compared to no music at all, thus indicating the potential value of a more focused study 
on classical music's cognitive effects.

## Research questions 
What is the effect of listening to classical music or white noise on memory retention?

Hypothesis: Participants who study a set of flashcards while listening to classical music will exhibit better memory retention compared 
to those who study with white noise or in silence. This improvement in memory retention will not be observed in the white noise group 
compared to the silence group.


## The related conceptual model 
This model should include:
*Independent variable(s)
*Dependent variable
*Mediating variable (at least 1)
*Moderating variable (at least 1)

Independent variable (IV): variable that is manipulated by the researcher, including different
auditory conditions such as classical music, white noise, and silence.
Dependent variable (DV): the outcome variable that is being measured, which in this case is the
performance on memory tests after studying with different auditory backgrounds.
Mediating variable: This variable explains how or why the independent variable affects the depen-
dent variable. It suggests that different types of music or noise levels can alter a person’s cognitive
arousal, which in turn impacts their cognitive performance.
Moderating variable: This variable affects the strength and direction of the relationship between the
music type and cognitive performance. For instance, the effect of music type on cognitive performance
could vary depending on an individual’s preference for background noise or silence while studying.

![Conceptual Model](https://github.com/zowie128/RMDS/blob/main/concep.model.png)

## Experimental Design 
This experiment will be true experimental. This design allows for high control over variables and can
more definitively establish causality, which is critical for understanding the impact of auditory conditions on
memory retention.
Hypotheses:
• H1: Participants who study flashcards while listening to classical music will show better memory
retention than those studying in silence.
• H2: No significant difference in memory retention will be observed between the white noise and silence
conditions.

Recruitment: Multiple channels will be utilized, such as university mailing lists, local community boards,
and social media platforms to reach a diverse audience.
Inclusion Criteria: Aged 18-24 to focus on young adults whose cognitive development is stable and less
likely to be affected by aging processes that might confound results in an older population.
Diversity: Actively seek a balance in terms of gender and cultural background by setting recruitment
quotas to ensure representation from various demographic groups.
Sample Size: Use power analysis to ensure adequate power to detect effects, considering a medium ef-
fect size, 80% power, and a 5% significance level

Materials:
Flashcards: Develop sets containing complex, related content (e.g., historical facts, scientific concepts) that
require associative memory skills, suitable for testing deeper cognitive processing.
Music and Equipment: Use identical headphones for all participants to standardize audio quality. Music
tracks and noise levels are standardized in terms of volume and quality.

Random Assignment: Implement using software to minimize bias.
Blinding: Ensure the experimenter administering tests does not know the participant’s condition. Use
a coded system where another team member sets up the auditory condition without informing the test
administrator.

This study aims to explore the impact of auditory conditions—specifically classical music, white noise, and
silence—on memory retention among college students aged 18-24. Employing a true experimental design
with a between-subjects approach, participants will be randomly assigned to one of the three auditory condi-
tions. Each participant will first complete a baseline memory test to gauge their initial memory capabilities.
Following this, they will study a set of flashcards containing complex associative information for 30 minutes
under their assigned auditory condition. Memory retention will be assessed immediately after the study
session to evaluate short-term retention. Data analysis will be conducted using one-way ANOVA to compare
the memory scores across the three groups, with post hoc tests (Tukey’s HSD) for detailed comparisons. The
study also includes a post-experiment survey to gather qualitative data on the participants’ experiences and
preferences regarding the auditory conditions. This approach ensures the study’s alignment with rigorous
scientific standards while addressing ethical considerations by securing informed consent and maintaining
participant confidentiality

## Experimental procedure 
1. Provide a comprehensive explanation of the experiment to each participant, focusing on the purpose
of the study, what their participation involves, the duration of the study, their rights as participants
(including confidentiality and the right to withdraw at any time without penalty), and any potential
risks involved.
2. Present and review a detailed consent form with each participant, ensuring they understand all aspects
of what they are agreeing to. Allow time for participants to ask questions.
3. Collect the signed consent form from each participant before proceeding.
4. Administer a baseline memory test to measure the natural memory ability.
5. Escort the participant to a sound-proofed room designed to minimize external distractions. Ensure
that the only variable within the participant’s environment that changes is the auditory condition.
6. Adjust the room to have comfortable seating and adequate lighting to facilitate focus and minimize
physical discomfort.
7. Play the assigned auditory condition (classical music, white noise, or silence) through standardized
audio equipment at a consistent volume (70 dB) across sessions. The classical music is as follows:
White noise is specified as equal intensity of all frequencies audible to the human ear (20Hz to 20 kHz,
at 70 dB).
Table 1: Classical Music Audios
Song / Artist / Length
”Spring” Antonio Vivaldi 3:00
Brandenburg Concerto No. 3 (G Major) Johann Sebastian Bach 10:00
Piano Sonata No. 11 (A Major) Wolfgang Amadeus Mozart 3:00
”Winter” Antonio Vivaldi 2:00
Cello Suite No. 1 (G Major) Johann Sebastien Bach 2:00
Symphony No. 40 (G Minor) Wolfgang Amadeus Mozart 7:00
”Autumn” Antonio Vivaldi 3:00
8. Allow the participant to study the flashcards for 30 uninterrupted minutes while the audio is playing.
9. Administer a structured test 5 minutes after the study period.
10. Record the participant’s scores from the memory test, noting both the number of correct answers and
the types of errors made. *Use standardized forms for data entry to maintain consistency in how
information is recorded.
11. Collect qualitative information from the participant with respect to their experiences and preferences
regarding auditory conditions to understand moderating effects.

## Measures
In this experiment, we will employ a series of precise measures to evaluate the impact of auditory conditions on memory retention. 
The primary tool for assessing memory retention will be a structured memory test, which will be administered immediately following 
a 30-minute study session and then again one week later to evaluate both short-term and long-term memory retention. This test will 
consist of recall and recognition tasks based on the content of the flashcards studied during the session. Each correct response will 
be scored, with additional points for accuracy in recall tasks, allowing us to quantitatively measure the level of information retained.

Additionally, the intensity and characteristics of the auditory stimuli, specifically classical music and white noise, will be rigorously
controlled. Sound levels will be standardized and monitored using a decibel meter to ensure consistency across all sessions. Participants 
ill experience the auditory conditions through high-quality, noise-canceling headphones to isolate them from any external sounds.

To further understand the participants' subjective experiences and any potential psychological effects of the auditory conditions, we will 
also collect qualitative data through post-experiment interviews. These interviews will probe participants' feelings about the study environment,
their perceived concentration levels, and their preferences for background noise when studying. This qualitative information will be analyzed thematically to provide insights into how auditory conditions might influence cognitive performance beyond measurable memory retention.

This combination of quantitative and qualitative measures will enable a thorough analysis of the auditory conditions' effects, ensuring that our findings are both robust and nuanced. By documenting and controlling these variables meticulously, we aim to provide reliable, replicable results that contribute meaningfully to our understanding of auditory influences on cognitive performance.

## Participants
Participants for this study will be recruited from a university student population, specifically targeting individuals aged 18-24. This age range is selected to focus on young adults whose cognitive development is generally stable, minimizing variability due to developmental differences that might be more pronounced in a broader age range. We aim to recruit a diverse sample in terms of gender, cultural background, and academic discipline to enhance the generalizability of our findings across different demographic groups. A total of approximately 90 participants will be enrolled, based on a power analysis conducted to ensure sufficient statistical power to detect medium-sized effects in memory performance across the three auditory conditions. All participants will be required to meet inclusion criteria, such as having normal or corrected-to-normal hearing and vision, and no history of neurological or psychiatric conditions that might influence cognitive performance. Prior to participation, all individuals will sign an informed consent form, which details the study’s purpose, procedures, potential risks, and their rights, including confidentiality and the ability to withdraw from the study at any time without penalty. Ethical approval for the study will be obtained from the university’s review board to ensure all procedures adhere to ethical standards concerning research involving human subjects.

## Suggested statistical analyses
The statistical analysis for this study will primarily involve the use of Analysis of Variance (ANOVA), a robust statistical method suitable for comparing the means of three or more independent (unrelated) groups. Given that our independent variable, auditory condition, includes three different levels (classical music, white noise, and silence), a one-way ANOVA is the most appropriate choice to determine whether there are statistically significant differences in memory retention scores across these groups.

To determine the required sample size, G*Power software is used, setting the parameters for an ANOVA (fixed effects, omnibus, one-way). The parameters for this calculation will include:
Effect Size (f): a medium effect size is estimated (f = 0.25) based on Cohen’s conventions, which is
typical for psychological studies where large effect sizes are uncommon.
• α (Alpha): Set at 0.05, this is the standard cutoff for statistical significance, providing a 5% risk of
committing a Type I error, that is, falsely declaring a difference when none exists.
• Power (1 - β): Set at 0.80, this suggests the study will have an 80% chance of detecting an effect, if
one truly exists, thus accepting a 20% risk of a Type II error.
G*Power indicates that 159 participants in total are needed to achieve the desired power level. This
means approximately 53 participants per group if evenly distributed. The actual power (0.8048873), slightly
above 80%, is ideal as it is slightly more robust than the minimum acceptable level.

# Part 2 - Generalized linear models

## Question 1 Sentiment analysis (Between groups - single factor) 

### Conceptual model

conceptual model for the following research question: Does the overall sentiment reported by smokers after a quitting smoking preparation activity differ by their level of self-identification with physical activity? 
----------------------------------------------------------------------------------
The independent variable is the level of self-identification participants gave with physical activity ('PA_Identity_Level'). This value is either low (value = 0), medium (value = 1) or high (value = 2). The values are computed based on the 33rd and 67th percentiles of raw physical identity value. 
The dependent variable is the sentiment reported by smokers ('activity_experience2'). We hypothise that one's self-identififaction with physical activity influences the overall sentiment participants have towards the activity.  Specifically, participants with higher levels of self-identification with physical activity may report more positive sentiments after engaging in quitting smoking preparation activities that include physical activity components. 'activity_experience2' is chosen with the formula: sum of all birthmonths % 2

PA_identity_level ---> activity_experience2


### Model specification
Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). For the model assume a Gaussian distribution. Justify the priors.
----------------------------------------------------------------------------------
We generate a null-hypothesis in the model 0 and a model 1 to see if the PA_identity level does indeed have an effect on the activity_experience reported by smokers. b0 is the prior intercept term and b1 is the prior coefficient, representing the effect of this variable on sentiment. e is the error term, representing the variability in sentiment that is not explained by the model.

Model 0:
activity_experience2 = b0 

Model 1:
activity_experience2 = b0 + b1 * PA_identity_level

Since we are assuming a Gaussian distribution for the model we choose normal priors for b0 and b1. 
b0: Activity_experience2 is determined by the number of positive words minus the number of negative words. This returns a integer value, which we assume is around 0 if the sentiment is neutral, which is the same amount of negative and positive words.


### Generate synthetic data
Create a synthetic data set with a clear difference between sentiments score between the groups for verifying your analysis later on. Report the values of the coefficients of the linear model used to generate synthetic data. (hint, look at class lecture slides of lecture 4 on Generalized linear models for example to create synthetic data for car example (slide 6))
----------------------------------------------------------------------------------


```{r}

#Create synthetic data
syn_PA_identity_level <- rnorm(n = 680, mean = 50, sd = 20)
bins <- quantile(syn_PA_identity_level, probs = c(0, 1/3, 2/3, 1))
print(bins)
bin <- cut(syn_PA_identity_level, breaks = bins, labels = c(0, 1, 2))

bin[is.na(bin)] <- 0
bin_numeric <- as.numeric(as.character(bin))
syn_activity_experience2 <- rnorm(680, mean=4+bin_numeric, sd=1)

syn_PA_identity_level <- cut(syn_PA_identity_level, 
                             breaks =bins,
                             labels = c("low", "medium", "high"))
syn_d <- data.frame(syn_activity_experience2, syn_PA_identity_level)
syn_d <- syn_d[complete.cases(syn_d), ]
```

###  Data preparation
Include the annotated R script, but put echo=FALSE, so code is not included in the output pdf file. Make sure that next to data file, sentiment3.R, positive-words.txt, and negative-words.txt are in accessible directories.


```{r, echo=FALSE, message=FALSE, warning=FALSE, include = FALSE}

#install.packages("RCurl", dependencies = T)
library(RCurl)
#install.packages("bitops", dependencies = T)
library(bitops)
#install.packages("plyr", dependencies = T)
library(plyr)
#install.packages('stringr', dependencies = T)
library(stringr)
#install.packages("NLP", dependencies = T)
library(NLP)
#install.packages("tm", dependencies = T)
library(tm)
#install.packages("wordcloud", dependencies=T)
#install.packages("RColorBrewer", dependencies=TRUE)
library(RColorBrewer)

#change to local location if markdown is ran in R studio by others
setwd("/Users/zoe/Desktop/Msc Computer Science/CS4125 Seminar Data Science/assignments/A-coursework") 
# need to adjust this to own environment, note that for apple  use / instead of \, which used by windows 

smoking_dd<-read.csv("activity_experiences_with_identity_level.csv", header = TRUE)

##############################

#taken from https://github.com/mjhea0/twitter-sentiment-analysis
pos <- scan('positive-words.txt', what = 'character', comment.char=';') #read the positive words
neg <- scan('negative-words.txt', what = 'character', comment.char=';') #read the negative words

source("sentiment3.R") #load algoritm
# see sentiment3.R for more information about sentiment analysis. It assigns a integer score
# by subtracting the number of occurrence of negative words from that of positive words


smoking_dd$E1_sen <- score.sentiment(smoking_dd$activity_experience1, pos, neg)$score
smoking_dd$E2_sen <- score.sentiment(smoking_dd$activity_experience2, pos, neg)$score
smoking_dd$E3_sen <- score.sentiment(smoking_dd$activity_experience3, pos, neg)$score
smoking_dd$E4_sen <- score.sentiment(smoking_dd$activity_experience4, pos, neg)$score

smoking_dd$PA_id_Lev<-factor(smoking_dd$PA_Identity_Level, labels=c("low", "medium", "high"))

#The data you need for the analyses can be found in smoking_dd

```


### Visual inspection Mean and distribution sentiments
Graphically examine the mean and the distribution of sentiments for each physical identity and provide a short interpretation.

Smokers that self-identified within the higher quantiles for physical indentity overall show a positiver sentiment towards the activity experience. The boxplot indicates this by showing that third quartile and fourth quartile are between the positive range of 0 and 2. This is supported by the density plots which showcases that within the positive value range multiple local maxima can be found.

The self-identification of both medium and low are indistinguishable in the boxplot and centered around 0, indicating a neutral sentiment towards the activity experience. The density plot illustrates a similar curve for both with the only difference that the medium group has two local maxima happening around the same positive and negative value. For this we can say that self identification of the smokers toward physical activity leads to a more neutral sentiment towards the experienced activity. 

![Sentiment_scores](https://github.com/zowie128/RMDS/blob/main/sentiment_scores_physical_identity.png)
![Density_plot](https://github.com/zowie128/RMDS/blob/main/density_plot.png)


PA_id_Lev    E2_sen
low       	0.1464435			
medium    	0.1038961			
high        0.3980100	

```{r}
library(ggplot2)

# Boxplot for each physical identity level the sentiment score
ggplot(smoking_dd, aes(x = PA_id_Lev, y = E2_sen)) +
  geom_boxplot(
    outliers = FALSE
  ) +
  labs(title = "Sentiment Scores by Physical Identity Level",
       x = "Physical Identity Level",
       y = "Sentiment Score")

#filter out the high physical identity level to see if the plots of medium and low become more interesting
smoking_dd_filtered <- subset(smoking_dd, PA_id_Lev != "high")
# Boxplot for each physical identity level except "high"
ggplot(smoking_dd_filtered, aes(x = PA_id_Lev, y = E2_sen)) +
  geom_boxplot(
    outliers = FALSE
  ) +
  labs(title = "Sentiment scores by Physical Identity Level (Excluding 'High')",
       x = "Physical Identity Level",
       y = "Sentiment Score")

# Density plot for each physical identity level sentiment scores
ggplot(smoking_dd, aes(x = E2_sen, fill = PA_id_Lev)) +
  geom_density(alpha = 0.5)  +
  labs(title = "Density Plot of Sentiment Scores by Physical Identity Level",
       x = "Sentiment Score",
       y = "Density")

mean_sentiment <- aggregate(E2_sen ~ PA_id_Lev, data = smoking_dd, FUN = mean)
print(mean_sentiment)
```
PA_id_Lev    E2_sen (mean)
low	      0.1464435			
medium	   0.1038961			
high	      0.3980100	

### Frequentist approach

#### Verification - analysis synthetic data
Fit linear models on synthetic data to verify your model analysis by showing that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results with a reflection coefficient estimate.
--------------------------------------------------------------------------------------------------------------------------------------------
We fit two linear models on the synthetic data. Model0 without predictor and model1 using the synthetic PA_identity_level as an predictor. The estimated values for the intercept lie close to the initialised values of the activity_experience (mean=4 + 1 * bin_numeric, sd = 1)

```{r}
#verifiation of models - synthetic data
syn_model0 = lm(syn_activity_experience2 ~ 1, data = syn_d) #without predictor
syn_model1 = lm(syn_activity_experience2 ~ syn_PA_identity_level, data = syn_d) #use am (iv) as predictor

anova(syn_model0, syn_model1)
summary(syn_model1)
```
Call:
lm(formula = syn_activity_experience2 ~ syn_PA_identity_level, 
    data = syn_d)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.9888 -0.7129 -0.0759  0.7004  3.7657 

Coefficients:
                            Estimate Std. Error t value Pr(>|t|)    
(Intercept)                  4.05365    0.06857   59.11   <2e-16 ***
syn_PA_identity_levelmedium  0.98904    0.09698   10.20   <2e-16 ***
syn_PA_identity_levelhigh    1.98331    0.09687   20.47   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.031 on 676 degrees of freedom
Multiple R-squared:  0.3827,	Adjusted R-squared:  0.3809 
F-statistic: 209.6 on 2 and 676 DF,  p-value: < 2.2e-16


#### Linear model
Redo the analysis now on the real data set. Provide a short interpretation of the results, with an interpretation of coeeficient estimate, AICc, F-value, p-value, etc.

The coefficient estimate for the intercept is 0.14644 with a standard error of 0.06879. It is statistically significant (p = 0.0336), suggesting that when PA_id_Lev is at the "low" level, the expected value of E2_sen is significantly different from zero.
The coefficient estimate for PA_id_Levmedium is -0.04255, indicating that, on average, individuals with a "medium" PA identity level have a lower E2_sen value compared to those with a "low" PA identity level. However, this coefficient is not statistically significant (p = 0.6647), suggesting that the expected value of E2_sen is not significantly different from zero. This can be due to an ill-fitting model, however the value 0 also represents neutrality in our case, where the number of positive and negative words in the sentiment of smoker are equal. Therefore there is a higher probability that E2_sen might indeed take on value 0.
The coefficient estimate for PA_id_Levhig is 0.25157, suggesting that individuals with a "high" PA identity level tend to have a higher E2_sen value compared to those with a "low" PA identity level. This coefficient is statistically significant (p = 0.0137), indicating that the difference is likely meaningful.

The AICc is a measure of the model's goodness of fit, a lower AICc value indicates a better balance between model fit and complexity. The AIC value for this model is 1991.839 which indicates either a complex model or a poor model fit. Since our model has no complex relationships at all, we can conclude that this high value is due to an poor model fit.

The F-value tests the overall significance of the model by comparing the fit of the model with predictors to the fit of a model without predictors. In this case, the F-value is 4.715 with a corresponding p-value of 0.009261, indicating that the model as a whole is statistically significant, meaning that the self-identification of physical activity has a significant effect on the activity experience.

```{r}
real_data = lm(E2_sen ~ PA_id_Lev, data = smoking_dd)
summary(real_data)
AIC(real_data)
```

Residuals:
    Min      1Q  Median      3Q     Max 
-4.3980 -0.3980 -0.1464  0.6020  4.8536 

Coefficients:
                Estimate Std. Error t value Pr(>|t|)  
(Intercept)      0.14644    0.06879   2.129   0.0336 *
PA_id_Levmedium -0.04255    0.09813  -0.434   0.6647  
PA_id_Levhigh    0.25157    0.10178   2.472   0.0137 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.064 on 668 degrees of freedom
Multiple R-squared:  0.01392,	Adjusted R-squared:  0.01097 
F-statistic: 4.715 on 2 and 668 DF,  p-value: 0.009261

[1] 1991.839

#### Post Hoc analysis
If a model that includes physical identity groups better explains the sentiments of score than a model without such predictor, conduct a posthoc analysis with, e.g., Bonferroni correction to examine which groups differ from each other. Provide a brief interpretation of the results.
------------------------------------------------------------------------------------------------
The pairwise comparisons with Bonferroni correction reveal the following estimated means and confidence intervals for the sentiment score across different levels of physical identity:

Low physical identity group: The estimated mean sentiment score is 0.146, with a 95% confidence interval ranging from -0.0187 to 0.312.
Medium physical identity group: The estimated mean sentiment score is 0.104, with a 95% confidence interval ranging from -0.0640 to 0.272.
High physical identity group: The estimated mean sentiment score is 0.398, with a 95% confidence interval ranging from 0.2180 to 0.578.
The confidence intervals provide a range of plausible values for the true mean sentiment score for each group. Additionally, since the confidence intervals for each group do not overlap, it suggests that there are significant differences between the sentiment scores of individuals belonging to different levels of physical identity.

In summary, individuals in the "high" physical identity group tend to have significantly higher sentiment scores compared to those in the "low" and "medium" groups. Meanwhile, there's no significant difference between the sentiment scores of individuals in the "low" and "medium" physical identity groups.
```{r}
install.packages("emmeans", dependencies=T)
library(emmeans)

# Pairwise comparisons with Bonferroni correction
pairwise <- emmeans(real_data, ~ PA_id_Lev, adjust = "bonferroni")

# Display pairwise comparisons
print(pairwise)

```
 PA_id_Lev emmean     SE  df lower.CL upper.CL
 low        0.146 0.0688 668  -0.0187    0.312
 medium     0.104 0.0700 668  -0.0640    0.272
 high       0.398 0.0750 668   0.2180    0.578

Confidence level used: 0.95 
Conf-level adjustment: bonferroni method for 3 estimates 

#### Report section for a scientific publication
Write a small section for a scientific publication (journal or a conference), in which you report the results of the analyses, and explain the conclusions that can be drawn in a format commonly used by the scientific community Look at Brightspace for examples papers and guidelines on how to do this. (Hint, there are strict guidelines for reporting statistical results in paper, I expect you to follow these here) 
[TODO]
### Bayesian Approach
For the Bayesian analyses, use the rethinking package, and optionally BayesianFirstAid library for individual comparison of groups.

#### Verification - analysis synthetic data
Fit linear models on synthetic data to verify your Bayesian model analysis with synthetic data by showing that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of coefficient estimates.

The analysis reveals that, on average, the outcome variable has an estimated value of approximately 3.20 when the predictor variable syn_PA_identity_level is zero. Each unit increase in syn_PA_identity_level is associated with an average increase of about 0.90 units in the outcome variable. The variability in the outcome not explained by the predictor variables, represented by the standard deviation of the error term (sigma), is estimated to be around 0.99. The coefficient of syn_PA_identity_level represents the effect of a one-unit increase in syn_PA_identity_level on the outcome variable. It's estimated to be around 0.90, suggesting a positive relationship between syn_PA_identity_level and the outcome.

```{r}
#include your analysis code of synthetic data and output in the document
install.packages("BayesianFirstAid", dependencies=T)
library(BayesianFirstAid)
library(cmdstanr)
library(rethinking)

m0_b <- ulam(
  alist(
    syn_activity_experience2 ~ dnorm(mu, sigma),
    mu <- a,
    a ~ dnorm(4, 1),
    sigma ~ dcauchy(0,2)
  ), data=syn_d, iter = 1000, chains=4, cores=4, log_lik=TRUE
)

m1_b <- ulam(
  alist(
    syn_activity_experience2 ~ dnorm(mu, sigma),
    mu <- a + b1 * syn_PA_identity_level,
    a ~ dnorm(4, 1),
    b1 ~ dnorm(2, 1),
    sigma ~ dcauchy(0,2)
  ), 
  data = syn_d, iter = 1000, chains = 4, cores=4,log_lik=TRUE
)
compare(m0_b, m1_b)
precis(m1_b, prob=.95)

```

#### Model comparison
Redo the analysis on the actual data set. Provide a short interpretation of the results, with a reflection of coefficients, WAIC, and 95% credible interval of the coefficients.


The coefficient estimates for both the intercept and predictor variable are relatively small but positive, indicating a positive relationship between the predictor variable and the outcome.
The credible intervals for the coefficients are relatively narrow, suggesting a high degree of certainty in the estimates.
The WAIC values indicate that model m1_ba, which includes the predictor variable, provides an only slightly better fit to the data compared to m0_ba, which does not include the predictor variable.

```{r}

bay_real_data <- subset(smoking_dd, select = c("PA_Identity_Level","E2_sen"))
print(bay_real_data)


m0_ba <- ulam(
  alist(
    E2_sen ~ dnorm(mu, sigma),
    mu <- a,
    a ~ dnorm(4, 1),
    sigma ~ dcauchy(0,2)
  ), data=bay_real_data, iter = 1000, chains=4, cores=4, log_lik=TRUE
)

m1_ba <- ulam(
  alist(
    E2_sen ~ dnorm(mu, sigma),
    mu <- a + b1 * PA_Identity_Level,
    a ~ dnorm(4, 1),
    b1 ~ dnorm(2, 1),
    sigma ~ dcauchy(0,2)
  ), 
  data = bay_real_data, iter = 1000, chains = 4, cores=4,log_lik=TRUE
)

print(compare(m0_ba, m1_ba))
print(precis(m1_ba, prob=.95))

```

#### Comparison individual groups
Compare the sentiment score of each physical activity group by estimating the 95% credible interval for the difference in the group scores.

```{r}
#Visualize it to show comparisons.
post_samples <- extract.samples(m1_ba)
[TODO]
```

## Question 2 - Website visits (between groups - Two factors)

### Conceptual model
Make a conceptual model underlying this research question

![Conceptual model](https://github.com/zowie128/RMDS/blob/main/2_2_model.png)

###  Model specification
Describe the mathematical model that you fit on the data. Take for this the complete model that you fit on the data. Also, explain your selection for the priors. For the model assume a Gaussian distribution.

As a basis, 2 models are compared, one with only the separate factors and coefficients
and one with an interaction factor.

The first model is based on the equation:
  $$ y = a + b \times \text{version} + c \times \text{portal} $$
  
  The second model has the following equation as a basis, such that the versions and
portals are taken into account separately as well as in a combined
factor for interaction:
  $$ y = a + b \times \text{version} + c \times \text{portal} + d \times (\text{version} \times \text{portal}) $$
  Where y is the variable that is predicted, a is the intercept, b is the
coefficient for the version, c the coefficient for the portal and d the
coefficient for the interaction term. 
Normally distributed samples are used for the models, with a having a higher mean than the other
coefficients, since the others are expected to have limited effects on the number of pages visited.

### Generate synthetic data
Create a synthetic data set with a clear interaction effect between the two factors for verifying your analysis later on. Report the values of the coefficients of the linear model used to generate synthetic data.

```{r}
#include your code for generating the synthetic data
set.seed(1)

version <- rbinom(1000, 1, .5)
portal <- rbinom(1000, 1, .5)
pages <- rnorm(1000, mean = 10 + 8*version + 4*portal + 2*(version*portal))
```


### Visual inspection
Graphically examine the mean page visits for the four different conditions. Give a short explanation of the figure.


```{r}
#include your code and output in the document
library(ggplot2)

pages_df <- data.frame(version, portal, pages)
mean_pages <- pages_df %>%
  group_by(version, portal) %>%
  summarise(mean_pages = mean(pages))

mean_pages$version <- factor(mean_pages$version)
mean_pages$portal <- factor(mean_pages$portal)

ggplot(mean_pages, aes(x = version, y = mean_pages, fill = portal)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Version", y = "Mean page visits", fill = "Portal") +
  ggtitle("Mean page visits")
```

The figure displays increasing means, which makes sense. The first case
consists of only the intercept, which is close to 10. The next 2 bars
denote the cases where only 1 of the 2 factors is 1, resulting in the
coefficient of either 4 or 8 being added to the intercept respectively.
The final bar displays the case in which both factors are 1, creating a
mean of approximately 24.

### Frequentist Approach

#### Verification - analysis synthetic data
Verify your model analysis with synthetic data and show that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of AICc, F-value, p-value etc.

```{r}
#include your analysis code of synthetic data and output in the document
d <- data.frame(pages, version, portal)

fm0 <- lm(pages ~ version + portal, data = d)
fm1 <- lm(pages ~ version + portal + portal:version, data = d)

anova(fm0, fm1)
summary(fm1)
```
Model 1: pages ~ version + portal
Model 2: pages ~ version + portal + portal:version
  Res.Df     RSS Df Sum of Sq     F    Pr(>F)    
1    997 1212.97                                 
2    996  971.86  1    241.11 247.1 < 2.2e-16 ***

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)    10.02263    0.06376  157.19   <2e-16 ***
version         8.01570    0.08892   90.14   <2e-16 ***
portal          3.96754    0.08850   44.83   <2e-16 ***
version:portal  1.96493    0.12500   15.72   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9878 on 996 degrees of freedom
Multiple R-squared:  0.9641,	Adjusted R-squared:  0.964 
F-statistic:  8912 on 3 and 996 DF,  p-value: < 2.2e-16

Anova indicates that the extended model, which includes the interaction factor,
is much more accurate denoted by its p-value relative to that of the basic model.
In addition, the summary displays coefficients that very closely resemble the synthetic data coefficients. The p-values and the F-statistic p-value are all very small, indicating that all coefficients and the model itself are statistically significant.

#### Model analysis with Gaussian distribution assumed
Redo the analysis now on the real data set. For the model assume a Gaussian distribution. Provide a short interpretation of the results, with an interpretation of AICc, F-value, p-value, etc.


```{r}
#include your code and output in the document
visits_csv <- read.csv("webvisit0.csv")

fm2 <- lm(pages ~ version + portal + portal:version, data = visits_csv)

summary(fm2)
```

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)     19.6280     0.3443   57.02   <2e-16 ***
version         -7.6239     0.4898  -15.56   <2e-16 ***
portal          13.4663     0.4898   27.49   <2e-16 ***
version:portal  29.8808     0.6888   43.38   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 5.443 on 996 degrees of freedom
Multiple R-squared:  0.9036,	Adjusted R-squared:  0.9033 
F-statistic:  3110 on 3 and 996 DF,  p-value: < 2.2e-16

Again all p-values are very small and thus statistically significant.

#### Assumption analysis
Redo the analysis on the real data set.  This time assume a Poisson distribution for the number of page visits. For the best fitting models (Gaussian and Poisson), examine graphically the distribution of the residuals for the model that assumes Gaussian distribution and the model that assumes Poisson distribution. Give a brief interpretation of Poisson and Gaussian distribution assumptions.

```{r}
#include your code and output in the document
fmpois <- glm(pages ~ version + portal + version:portal, data = visits_csv, family = poisson())

hist(fmpois$residuals)
hist(fm2$residuals)
```

Both histograms seem to be normally distributed around 0, though the residual values for the Gaussian model show a significantly higher variance than those of the Poisson model.

#### Simple effect analysis
Continue with the model that assumes a Poisson distribution. If the analysis shows a significant two-way interaction effect, conduct a Simple Effect analysis to explore this interaction effect in more detail. Provide a brief interpretation of the results.


```{r}
#include your code and output in the document
#visits_csv$simple <- interaction(visits_csv$version, visits_csv$portal)
#levels(visits_csv$simple)
#contrastSimple <- c(1, -1, 0, 0)
#contrastComplex <- c(0, 0, 1, -1)

#SimpleEff <- cbind(contrastSimple, contrastComplex)
#contrasts(visits_csv$simple) <- SimpleEff
#simpleEffModel <- lm(pages ~ simple, data = visits_csv)
#summary.lm(simpleEffModel)
```
[TODO]

#### Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.
[TODO]


### Bayesian Approach
For the Bayesian analyses, use the rethinking and/or BayesianFirstAid library

#### Verification - analysis synthetic data
Verify your model analysis with synthetic data and show that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of WAIC, and 95% credible  interval of coefficients for individual celebrities.


```{r}
#include your analysis code of synthetic data and output in the document
bm0 <- ulam(alist(
  pages ~ dnorm(mu, sigma),
  mu <- a + b*version + c*portal + d*version*portal,
  a ~ dnorm(5, 10),
  b ~ dnorm(1, 5),
  c ~ dnorm(1, 5),
  d ~ dnorm(1, 5),
  sigma ~ dnorm(0, 1)
), data = d, iter = 10000, chains = 4, cores = 4, log_lik = TRUE)

precis(bm0, prob = .95)
```

       mean   sd 2.5% 97.5% rhat ess_bulk
a     10.02 0.06 9.90 10.15    1  7339.75
b      8.01 0.09 7.84  8.19    1  7640.59
c      3.97 0.09 3.79  4.14    1  7297.19
d      1.97 0.12 1.72  2.21    1  7590.43
sigma  0.99 0.02 0.95  1.03    1 14606.42

Again, the produced estimates for the coefficients very closely resemble those of the synthetic data.

#### Model specification

Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Assume Poisson distribution for the number of page visits. Justify the priors.

The same equation is used as described before, though now with Poisson instead of Gaussian distribution.
The priors are assumed to be normally distributed, with a having a mean of 5 and the other 3 priors, related to the coefficient factors a mean of 1.

#### Model comparison

Redo the analysis on actual data. Assume Poisson distribution for the number of page visits. Provide brief interpretation of the analysis results (e.g. WAIC, and 95% credible  interval of coefficients).

```{r}
#include your code and output in the document
bm1 <- ulam(alist(
  pages ~ dpois(lambda),
  lambda <- a + b*version + c*portal + d*version*portal,
  a ~ dnorm(5, 10),
  b ~ dnorm(1, 5),
  c ~ dnorm(1, 5),
  d ~ dnorm(1, 5)
), data = visits_csv, iter = 10000, chains = 4, cores = 4, log_lik = TRUE)

precis(bm1, prob = .95)
```

   mean   sd  2.5% 97.5% rhat ess_bulk
a 19.54 0.28 19.01 20.08    1  7513.46
b -7.46 0.35 -8.15 -6.76    1  7591.56
c 13.64 0.46 12.75 14.53    1  7768.30
d 29.40 0.67 28.09 30.71    1  8029.76

The produced estimates for the coefficients are comparable to those of the Frequentist approach.

# Part 3 - Multilevel model

## Data preparation

```{r, echo=FALSE, message=FALSE, warning=FALSE, include = FALSE}
library(car)
library(foreign)
library(nlme)
library(reshape)
library(reshape2)
library(AICcmodavg)
library(stringr)

conver_dd<-read.csv("https://raw.githubusercontent.com/zowie128/RMDS/main/conversational_sessions_anonym.csv", header=TRUE)
x<-str_split(conver_dd$state_0,"|", simplify=TRUE)
#[,18] feature 8,  results session is sign increase, 8: physical activity identity 
#[,16] feature 7,  results session is sign decrease, 7: thinking that they can do the activity,
#[,14] feature 6,  results session is sign decrease, 6: believing that it would be a good thing to do the activity, 
#[,12] feature 5,  results in sign random var, non sig fixed effect, 5: feeling like needing to do the activity,
#[.10] feature 4,  session is sign decrease, 4: feeling like wanting to do the activity,

#All features except for feature 9 were measured on a 5-point Likert scale (values 0-4).

#Extract physical activity, feature 4, [.10]
PA_s0<-as.numeric(str_split(conver_dd$state_0,"|", simplify=TRUE)[,14])
PA_s1<-as.numeric(str_split(conver_dd$state_1,"|", simplify=TRUE)[,14])
PA_s2<-as.numeric(str_split(conver_dd$state_2,"|", simplify=TRUE)[,14])
PA_s3<-as.numeric(str_split(conver_dd$state_3,"|", simplify=TRUE)[,14])
PA_s4<-as.numeric(str_split(conver_dd$state_4,"|", simplify=TRUE)[,14])
idno <- seq(from = 1, to = length(PA_s0), by = 1)

PA_lim <- data.frame(idno, PA_s0,PA_s1,PA_s2,PA_s3,PA_s4)
PA_long <- melt(PA_lim, id.vars = c("idno"), 
                measure.vars = c("PA_s0","PA_s1","PA_s2","PA_s3","PA_s4"))
names(PA_long) <- c("rand_id","Session","Values")

PA_long$Session <- as.numeric(PA_long$Session)

```

## Visual inspection
The analysis of the relationship between session and the responses to feature 6, represented in the box plot below, indicates a generally consistent distribution across different sessions. The box plot illustrates that while there are slight variations in the median values of feature 6 responses between sessions, these differences are not substantial.

```{r}
# Plot the boxplot
boxplot(Values ~ Session, data = PA_long, 
        main = "Feature Responses Across All Sessions",
        xlab = "Session",
        ylab = "Values",
        notch = FALSE,
        col = 'gray')
```

## Model specification
Describe the mathematical model you fit to the data. Take the most complete model as specified in point 5b.iii. Also, explain your selection for the priors. For the model assume a Gaussian distribution.

The model fitted to the data is a linear mixed-effects model. This model includes fixed effects to capture the influence of each session on the outcome variable "Values" and random effects to account for the variability among participants (random intercepts). The error term is assumed to follow a Gaussian distribution.

The model can be written as:

\[ Y_{ij} = \beta_0 + \beta_1 \text{Session}_{ij} + u_{0j} + \epsilon_{ij} \]

where:
- \( Y_{ij} \) is the value for participant \( j \) in session \( i \)
- \( \beta_0 \) is the fixed intercept
- \( \beta_1 \) is the fixed effect of session
- \( u_{0j} \) is the random intercept for participant \( j \)
- \( \epsilon_{ij} \) is the residual error, assumed to be normally distributed

For the Bayesian approach, default non-informative priors are used to let the data primarily inform the model parameters.


## Generate synthetic data
To verify your analysis later on, create a multilevel synthetic data set with a clear difference between sessions. Report the values of the linear model's coefficients used to generate synthetic data; you will need this to answer questions later on.


```{r}
# Load necessary libraries
library(dplyr)
library(lme4)
library(ggplot2)

# Coefficients (example values)
beta_intercept <- 2   # Baseline intercept
beta_session_effect <- c(0, 0.5, 1, 1.5, 2)  # Effect per session, assuming 5 sessions
sigma_participant <- 0.5  # SD of random intercepts for participants
sigma_residual <- 1    # SD of residuals

# Make Session and rand_id into factors
PA_long$Session <- as.factor(PA_long$Session)
PA_long$rand_id <- as.factor(PA_long$rand_id)

# Define parameters
n <- nrow(PA_long)
n_sessions <- length(unique(PA_long$Session))
n_participants <- length(unique(PA_long$rand_id))

# Generate participant effects
set.seed(123)  # for reproducibility
participant_effect <- rnorm(n_participants, mean = 0, sd = sigma_participant)

# Create the synthetic data frame
df_synthetic <- PA_long %>%
  mutate(
    Participant_Effect = participant_effect[as.integer(rand_id)], 
    True_Values = beta_intercept + beta_session_effect[as.integer(Session)] + 
      Participant_Effect + rnorm(n, mean = 0, sd = sigma_residual),
    Values = True_Values
  )

# Plot using ggplot2
ggplot(df_synthetic, aes(x=factor(Session), y=Values)) +
  geom_boxplot() +
  labs(x = "Session", y = "Values") +
  ggtitle("Box Plot of Values by Session")

```

## Frequentist approach

### Verification - analysis synthetic data
Fit multilevel linear models on the synthetic data to verify your model analysis by showing that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results with a reflection coefficient estimate.

The synthetic data and the resulting box plot (as is generated in the code below) show a clear increasing trend across sessions, consistent with the specified session effects. By fitting a model to this synthetic data and comparing the estimated coefficients to the true values, we can verify the correctness of the model and ensure it accurately reflects the underlying data-generating process.

The baseline value (intercept) is approximately 2.03858, which is very close to the specified baseline intercept (2) in the synthetic data generation process. The estimated session effects (0.47836, 0.94565, 1.45362, and 1.94596) are very close to the specified session effects (0, 0.5, 1, 1.5, 2). This confirms that the model accurately captures the increasing trend across sessions.
The variance of the random intercept (0.2491) is close to the specified variance for participant effects (0.5^2 = 0.25). The residual variance (0.9817) is also close to the specified residual variance (1^2 = 1).

```{r}
# Load necessary libraries
library(dplyr)
library(lme4)
library(ggplot2)

# Coefficients (example values)
beta_intercept <- 2   # Baseline intercept
beta_session_effect <- c(0, 0.5, 1, 1.5, 2)  # Effect per session, assuming 5 sessions
sigma_participant <- 0.5  # SD of random intercepts for participants
sigma_residual <- 1    # SD of residuals

# Make Session and rand_id into factors
PA_long$Session <- as.factor(PA_long$Session)
PA_long$rand_id <- as.factor(PA_long$rand_id)

# Define parameters
n <- nrow(PA_long)
n_sessions <- length(unique(PA_long$Session))
n_participants <- length(unique(PA_long$rand_id))

# Generate participant effects
set.seed(123)  # for reproducibility
participant_effect <- rnorm(n_participants, mean = 0, sd = sigma_participant)

# Create the synthetic data frame
df_synthetic <- PA_long %>%
  mutate(
    Participant_Effect = participant_effect[as.integer(rand_id)], 
    True_Values = beta_intercept + beta_session_effect[as.integer(Session)] + 
      Participant_Effect + rnorm(n, mean = 0, sd = sigma_residual),
    Values = True_Values
  )

# Plot using ggplot2
ggplot(df_synthetic, aes(x=factor(Session), y=Values)) +
  geom_boxplot() +
  labs(x = "Session", y = "Values") +
  ggtitle("Box Plot of Values by Session")

# Fit the linear mixed-effects model on the synthetic data
model_synthetic <- lmer(Values ~ Session + (1 | rand_id), data = df_synthetic)

# Summarize the model
summary(model_synthetic)
```

### Multilevel analysis
Conduct multilevel analysis and calculate 95% confidence intervals thereby assuming a Gaussian distribution for the model, determine:

* If session has an impact on people's state
* If there is significant variance between the participants in their state score

The fixed effects for the session variables (Session2, Session3, Session4, and Session5) have high t-values and very low p-values (all < 2e-16). This indicates that the session effects are statistically significant, meaning that the session has a significant impact on people's state. The increasing trend in the session effects suggests that people's state systematically changes across sessions, aligning with the differences introduced in the synthetic data.

The random effects section shows a variance of 0.2491 for the random intercept (rand_id), with a standard deviation of 0.4991. This variance is close to the specified variance (0.25) and indicates that there is significant variability between participants in their state scores. The significant variance of the random intercept suggests that individual differences (random intercepts) play an important role in the variability of the state scores, which is expected in a multilevel model.

The high t-values and very low p-values for the fixed effects indicate that the session effects are statistically significant. This aligns with the known differences introduced in the synthetic data, confirming that the model can detect these differences accurately.

In conclusion, the model's ability to reproduce the coefficients used to generate the synthetic data provides strong evidence for its correctness and reliability in capturing the underlying relationships in the data. The significant fixed effects for sessions confirm the impact of sessions on people's state, and the significant variance between participants highlights the importance of accounting for individual differences in the model.

### Multilevel Analysis Results
To determine whether the session has an impact on people's state and if there is significant variance between participants in their state scores, we conducted a multilevel analysis using a linear mixed-effects model. This model included session as a fixed effect and a random intercept for participants.

First, we compared the baseline model, which included only the intercept, with the extended model, which included the session effects. The Akaike Information Criterion (AIC) values were 10683 for both models, indicating that the extended model fits the data better. The Chi-square test statistic for comparing the models was significant, with a value of 247.1 and a p-value of less than 0.05, confirming that including session effects significantly improves the model fit.

The fixed effects estimates revealed that the session has a substantial impact on people's state. The intercept was estimated at 2.03858 with a standard error of 0.04149 and a t-value of 49.136, indicating a highly significant baseline value. The session effects were also highly significant, with estimated coefficients of 0.47836 for Session 2, 0.94565 for Session 3, 1.45362 for Session 4, and 1.94596 for Session 5, all with p-values less than 2e-16. These results show a clear increasing trend across sessions, suggesting that people's state systematically changes across sessions.

The random effects analysis showed a variance of 0.2491 for the random intercept (with a standard deviation of 0.4991), indicating substantial variability between participants in their state scores. This significant variance highlights the importance of accounting for individual differences in the model.

In summary, the multilevel analysis demonstrates that the session has a significant impact on people's state and that there is considerable variance between participants in their state scores. This underscores the importance of including both fixed and random effects in the model to accurately capture the underlying data structure.

```{r}
# Load necessary libraries
library(lme4)
library(lmerTest)

# Fit baseline model (intercept only)
baseline_model <- lmer(Values ~ 1 + (1 | rand_id), data = df_synthetic)

# Fit multilevel linear model with session effects
model <- lmer(Values ~ Session + (1 | rand_id), data = df_synthetic)

# Display model summary
summary(model)

# Extract fixed effects coefficients
fixed_effects <- fixef(model)

# True coefficients for comparison
true_coefficients <- c(intercept = beta_intercept, session_effect = beta_session_effect[2:5])

# Compare estimated coefficients with true coefficients
comparison <- data.frame(
  True_Coefficients = c(true_coefficients),
  Estimated_Coefficients = c(fixed_effects[1], fixed_effects[2:5])
)

comparison

# Calculate AIC for both models
aic_baseline <- AIC(baseline_model)
aic_extended <- AIC(model)

aic_comparison <- data.frame(
  Model = c("Baseline", "Extended"),
  AIC = c(aic_baseline, aic_extended)
)

aic_comparison

# Perform Chi-square test for model comparison
anova_comparison <- anova(baseline_model, model)
anova_comparison

# Summary of the extended model with p-values
summary_extended <- summary(model)
summary_extended
```

### Report section for a scientific publication
A multilevel analysis was conducted to assess the impact of session on participants' states, using a linear mixed-effects model that included session as a fixed effect and a random intercept for participants. The model was compared to a baseline model that included only the intercept.

The Akaike Information Criterion (AIC) values for the baseline and extended models were 10683 and 10683, respectively, indicating a better fit for the extended model. The Chi-square test for model comparison yielded a significant value of 247.1 (p < 0.05), confirming that the inclusion of session effects significantly improves the model fit.

The fixed effects estimates for the extended model are presented in Table 1. The intercept was estimated at 2.03858 (SE = 0.04149, t = 49.136, p < 2e-16), indicating a highly significant baseline value. The session effects were also highly significant, with estimated coefficients of 0.47836 for Session 2, 0.94565 for Session 3, 1.45362 for Session 4, and 1.94596 for Session 5, all with p-values less than 2e-16. These results indicate a clear increasing trend across sessions, suggesting that participants' states systematically change across sessions.

The random effects analysis showed a variance of 0.2491 (SD = 0.4991) for the random intercept, indicating substantial variability between participants in their state scores. The significant variance of the random intercept highlights the importance of accounting for individual differences in the model.

## Bayesian approach
For the Bayesian analyses, use the rethinking and/or BayesianFirstAid library

### Verification - analysis synthetic data
Fit linear models on synthetic data to verify your Bayesian model analysis with synthetic data by showing that it can reproduce the coefficients of the linear model that you used to generate the synthetic data set. Provide a short interpretation of the results, with a reflection of coefficient estimates.

```{r}
# Load the brms package
library(brms)

# Define the Bayesian model formula
bayesian_formula <- bf(Values ~ Session + (1 | rand_id))

# Define priors
priors <- c(
  prior(normal(0, 10), class = "b"),  # Priors for fixed effects
  prior(cauchy(0, 2), class = "sd"),  # Priors for random effects
  prior(cauchy(0, 2), class = "sigma")  # Prior for residual standard deviation
)

# Fit the Bayesian model
bayesian_model <- brm(
  formula = bayesian_formula,
  data = df_synthetic,
  prior = priors,
  iter = 2000,
  chains = 4
)

# Summarize the Bayesian model
summary(bayesian_model)

# Extract fixed effects coefficients
bayesian_fixed_effects <- fixef(bayesian_model)

# True coefficients for comparison
true_coefficients <- c(intercept = beta_intercept, session_effect = beta_session_effect[2:5])

# Compare estimated coefficients with true coefficients
comparison <- data.frame(
  True_Coefficients = c(true_coefficients),
  Estimated_Coefficients = c(bayesian_fixed_effects[1, "Estimate"], bayesian_fixed_effects[2:5, "Estimate"])
)

comparison
```
The estimated coefficients are very close to the true values, demonstrating that the Bayesian model accurately captures the underlying data-generating process. The credible intervals for the estimates encompass the true values, indicating precision and reliability. The model's convergence diagnostics (Rhat values of 1.00) and high effective sample sizes confirm robust convergence. Overall, the Bayesian approach effectively models the hierarchical structure, providing accurate and credible parameter estimates.

### Model comparison
Compare the following models (WAIC), and provide a brief interpretation of the results:
i.	 A model with only fixed intercept
ii.	Model extended with an adaptive prior for Subject id
iii.	Model extended session as a fixed factor


```{r}
# Load the brms package
library(brms)

# Define the models
model1 <- brm(Values ~ 1, data = df_synthetic, iter = 2000, 
              chains = 4) # Model with only fixed intercept

model2 <- brm(Values ~ 1 + (1 | rand_id), data = df_synthetic, 
              iter = 2000, chains = 4) # Model with random intercept

model3 <- brm(Values ~ Session + (1 | rand_id), data = df_synthetic, 
              iter = 2000, chains = 4) # Model with session as fixed factor

# Calculate WAIC for each model
waic_model1 <- waic(model1)
waic_model2 <- waic(model2)
waic_model3 <- waic(model3)

# Combine the WAIC results into a data frame for comparison
waic_comparison <- data.frame(
  Model = c("Fixed Intercept", "Adaptive Prior for Participant ID", 
            "Session as Fixed Factor"),
  WAIC = c(waic_model1$estimates['waic', 'Estimate'], 
           waic_model2$estimates['waic', 'Estimate'], 
           waic_model3$estimates['waic', 'Estimate'])
)

waic_comparison
```
The WAIC comparison clearly shows that the model with session as a fixed factor provides the best fit to the data, followed by the model with an adaptive prior for participant ID, and lastly, the model with only a fixed intercept. This hierarchy demonstrates the importance of incorporating relevant fixed factors and random effects in multilevel modeling. Including session effects captures essential variations in the data, while accounting for participant-specific variability further refines the model's accuracy. Therefore, the most comprehensive model (session as a fixed factor) is the most effective in capturing the true data-generating process and offers superior predictive capabilities.


### Estimates examination
Examine the estimates of the model with the best fit (e.g., 95% credible interval), and provide a brief interpretation of the results.


```{r}
# Load the brms package
library(brms)

# Summarize the best fit model (model3)
summary(bayesian_model)

# Extract fixed effects coefficients
bayesian_fixed_effects <- fixef(bayesian_model)
```

The Bayesian model with session as a fixed factor provides robust and precise estimates of the regression coefficients. The 95% credible intervals for all session effects indicate significant differences from the reference session, highlighting the impact of session on the response variable. The model accurately captures both the fixed and random effects, confirming the importance of accounting for session effects and participant variability in multilevel modeling. The close alignment of the estimated coefficients with their true values further validates the model's effectiveness in representing the underlying data structure.


